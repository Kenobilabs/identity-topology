#default remote
run.location = remote
# keep run location remote, if you are running on any cluster
source.type = rabbit



#source Kakfa Point
#source RabbitMq points
rabbitmq.shard.count=1

#heartbeat of rabbit, default 60
rabbitmq.heartbeat=60

input.rabbitmq.queueName0=detections
input.rabbitmq.host0=10
input.rabbitmq.port0=5672
input.rabbitmq.username0=guest
input.rabbitmq.password0=guest
input.rabbitmq.prefetchCount0=100
input.rabbitmq.ha.hosts0=10.
input.rabbitmq.requeueOnFail0=true
input.rabbitmq.virtualhost0=/
 
#destination 
destination.type=kafka
 
#destination
destinationKafkaURL=192.168.70.101:9092
outputTopic = destination-cloud-string

#new producer properties
batch.size=16384
linger.ms=1
buffer.memory=33554432

bolt.ssl.truststore.location=/var/kafkaSsl/clientKeys/truststore.jks
bolt.ssl.truststore.password=test

#keystore

bolt.ssl.keystore.location=
bolt.ssl.keystore.password=
bolt.ssl.key.password=
 
 
# Parallelism, Dont modify until complete understanding
# no of nodes
topology.workers=1
# no of executors
spoutParallelCount=1
boltParallelCount=1
# metrics
metricsParallelCount=1


# Rate Limiting / Sampling
# 'Yes'  for enabling rateLimiting or 'No' to disable
rate.limit=No

# Choose between the types, 'percent' for specifying Percentage of allowed messages/tuples for every 100 count , 'value' for specifying tuples/messages per minute
# percent or value
rate.type=percent
# Percentage Count , between 0 and 100 no decimals
percent.limit=50
# ValueCount , messages/tuples per minute (max value allowed is LONG.MAX)
value.limit=20

#encoding  org.apache.kafka.common.serialization.ByteArraySerializer for bytes and org.apache.kafka.common.serialization.StringSerializer for String 

serializerEncodingValue=org.apache.kafka.common.serialization.ByteArraySerializer
# Field Name , bytes for bytes , str for StringSchema
partitionFieldName = bytes

# raw for RawScheme (bytes) , string for StringScheme
schemeType = raw
 
#Update# keep topologyName and StreamName unique every time.
topology.name = identity-v5-rabbit-kafka
streamName = identity-v5-rabbit-kafka


#Mostly static values # keep topology.name and StreamName unique every time.
#options 1, -1 or 0
requiredAcks = 1        
topology.message.timeout.secs=300
topology.max.spout.pending=1
message.send.max.retries=0

#statsD
# yes or no
statsd=yes
metrics.statsd.host=localhost
metrics.statsd.port=8125
# default  storm.metrics
metrics.statsd.prefix=cpe