#default remote
run.location = local
# keep run location remote, if you are running on any cluster
source.type = kafka

#source Kakfa Point
sourceZooKeeperURL=192.168.70.101:2181
sourceBrokerId=192.168.70.101:9092
inputTopic = source-cloud-string
#Kafka consumer fetch size 
# default 1048576 , dont exceed
kafka.consumer.fetch.size.byte=1048576
#Kafka consumer buffer size 
# default 1048576 , dont exceed
kafka.consumer.buffer.size.byte=1048576
#Kafka consumer default buffer size

#SSL
spout.ssl.truststore.location=/var/kafkaSsl/clientKeys/truststore.jks
spout.ssl.truststore.password=test

#keystore

spout.ssl.keystore.location=
spout.ssl.keystore.password=
spout.ssl.key.password=
#destination 
destination.type=kafka

#destination
destinationKafkaURL=192.168.70.101:9092
outputTopic = destination-cloud-string

#new producer properties
batch.size=16384
linger.ms=1
buffer.memory=33554432

bolt.ssl.truststore.location=/var/kafkaSsl/clientKeys/truststore.jks
bolt.ssl.truststore.password=test

#keystore

bolt.ssl.keystore.location=
bolt.ssl.keystore.password=
bolt.ssl.key.password=
 
  
# Parallelism, Dont modify until complete understanding
# no of nodes
topology.workers=1
# no of executors
spoutParallelCount=1
boltParallelCount=1
# metrics
metricsParallelCount=1


# Rate Limiting / Sampling
# 'Yes'  for enabling rateLimiting or 'No' to disable
rate.limit=No

# Choose between the types, 'percent' for specifying Percentage of allowed messages/tuples for every 100 count , 'value' for specifying tuples/messages per minute
# percent or value
rate.type=percent
# Percentage Count , between 0 and 100 no decimals
percent.limit=40
# ValueCount , messages/tuples per minute (max value allowed is LONG.MAX)
value.limit=20

#encoding  org.apache.kafka.common.serialization.ByteArraySerializer for bytes and org.apache.kafka.common.serialization.StringSerializer for String 

serializerEncodingValue=org.apache.kafka.common.serialization.ByteArraySerializer
# Field Name , bytes for bytes , str for StringSchema
partitionFieldName = bytes

# raw for RawScheme (bytes) , string for StringScheme
schemeType = raw

#Mostly static values # keep topology.name and StreamName unique everytime.
topology.name = identity-v3-kafka-kafka
streamName = identity-v3-kafka-kafka
#options 1, -1 or 0
requiredAcks = 1 
topology.message.timeout.secs=300
topology.max.spout.pending=1
message.send.max.retries=0

#statsD
# yes or no
statsd=yes
metrics.statsd.host=localhost
metrics.statsd.port=8125
# default  storm.metrics
metrics.statsd.prefix=cpe